{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 256, 32)           3200      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 28,162\n",
      "Trainable params: 28,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from collections import namedtuple\n",
    "from keract import get_activations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import _pickle as cPickle\n",
    "\n",
    "import utils\n",
    "\n",
    "cfg = {}\n",
    "cfg['SGD_BATCHSIZE']    = 64\n",
    "cfg['NUM_EPOCHS']       = 1\n",
    "cfg['FULL_MI']          = True\n",
    "cfg['ACTIVATION'] = 'relu'\n",
    "cfg['SAVE_DIR'] = 'rawdata/lstm_model'\n",
    "\n",
    "ARCH_NAME =  'lstm'\n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(10)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 100\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 256\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "Y_train = keras.utils.np_utils.to_categorical(y_train, nb_classes).astype('float32')\n",
    "Y_test  = keras.utils.np_utils.to_categorical(y_test, nb_classes).astype('float32')\n",
    "\n",
    "Dataset = namedtuple('Dataset',['X','Y','y','nb_classes'])\n",
    "trn = Dataset(X_train, Y_train, y_train, nb_classes)\n",
    "tst = Dataset(X_test , Y_test, y_test, nb_classes)\n",
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "if not os.path.exists(cfg['SAVE_DIR']):\n",
    "            print(\"Making directory\", cfg['SAVE_DIR'])\n",
    "            os.makedirs(cfg['SAVE_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = [keras.callbacks.ModelCheckpoint(filepath='rawdata/lstm_model/model_{epoch:04d}.hdf5', save_weights_only=False)]\n",
    "# r = model.fit(X_train, Y_train, \n",
    "#               batch_size = cfg['SGD_BATCHSIZE'],\n",
    "#               epochs = cfg['NUM_EPOCHS'],\n",
    "#               validation_split = 0.2)\n",
    "              # validation_data=(tst.X, tst.Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      " 8256/20000 [===========>..................] - ETA: 2:28 - loss: 0.6711 - acc: 0.5802"
     ]
    }
   ],
   "source": [
    "def do_report(epoch):\n",
    "    # Only log activity for some epochs.  Mainly this is to make things run faster.\n",
    "    if epoch < 20:       # Log for all first 20 epochs\n",
    "        return True\n",
    "    elif epoch < 100:    # Then for every 5th epoch\n",
    "        return (epoch % 5 == 0)\n",
    "    elif epoch < 200:    # Then every 10th\n",
    "        return (epoch % 10 == 0)\n",
    "    else:                # Then every 100th\n",
    "        return (epoch % 100 == 0)\n",
    "\n",
    "cur_dir = cfg['SAVE_DIR']\n",
    "# i = 0\n",
    "# for epochfile in sorted(os.listdir(cur_dir)):\n",
    "#     fname = cur_dir + \"/\" + epochfile\n",
    "#     model = keras.models.load_model(fname)\n",
    "for i in range(0,5000):\n",
    "    model.fit(X_train, Y_train, \n",
    "              batch_size = cfg['SGD_BATCHSIZE'],\n",
    "              epochs = cfg['NUM_EPOCHS'],\n",
    "              validation_split = 0.2)\n",
    "    \n",
    "    if do_report(i):\n",
    "        data = {\n",
    "            'activity_tst' : []    # Activity in each layer for test set\n",
    "            }\n",
    "        \n",
    "        for layer in model.layers:\n",
    "            if layer.name == 'embedding_1':\n",
    "                continue\n",
    "\n",
    "            intermediate_layer_model = keras.models.Model(inputs=model.input, outputs=model.get_layer(layer.name).output)\n",
    "            intermediate_output = intermediate_layer_model.predict(X_train)  \n",
    "\n",
    "            data['activity_tst'].append(intermediate_output)\n",
    "\n",
    "            del intermediate_layer_model\n",
    "\n",
    "        fname = 'rawdata/relu_lstm' + \"/epoch%08d\"% i\n",
    "        print(\"Saving\", fname)\n",
    "        with open(fname, 'wb') as f:\n",
    "            cPickle.dump({'ACTIVATION':cfg['ACTIVATION'], 'epoch':i, 'data':data}, f) \n",
    "            \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc(\"savefig\", dpi=300)\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_EPOCHS = 5000\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "# summarize history for accuracy\n",
    "axes[0].plot(range(1,NUM_EPOCHS+1), r.history['acc'], '-x')\n",
    "axes[0].plot(range(1,NUM_EPOCHS+1), r.history['val_acc'], '-+')\n",
    "axes[0].set_title('Model accuracy')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "# axes[0].set_xticks(range(1,NUM_EPOCHS+1))\n",
    "axes[0].grid(linestyle='-')\n",
    "axes[0].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "axes[1].plot(range(1,NUM_EPOCHS+1), r.history['loss'], '-x')\n",
    "axes[1].plot(range(1,NUM_EPOCHS+1), r.history['val_loss'], '-+')\n",
    "axes[1].set_title('Model loss')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "# axes[1].set_xticks(range(1,NUM_EPOCHS+1))\n",
    "axes[1].grid(linestyle='-')\n",
    "axes[1].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.savefig('IMDB_acc_loss_plot', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
