{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import _pickle as cPickle\n",
    "from collections import defaultdict, OrderedDict, namedtuple\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import keras.backend as K\n",
    "\n",
    "import kde\n",
    "import simplebinmi\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "matplotlib.rc(\"savefig\", dpi=300)\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import utils\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(10)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 100\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 256\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "Y_train = keras.utils.np_utils.to_categorical(y_train, 2).astype('float32')\n",
    "Y_test  = keras.utils.np_utils.to_categorical(y_test, 2).astype('float32')\n",
    "\n",
    "Dataset = namedtuple('Dataset',['X','Y','y','nb_classes'])\n",
    "trn = Dataset(X_train, Y_train, y_train, 2)\n",
    "tst = Dataset(X_test , Y_test, y_test, 2)\n",
    "\n",
    "# calc MI for train and test. Save_activations must have been run with cfg['FULL_MI'] = True\n",
    "FULL_MI = False\n",
    "\n",
    "# Which measure to plot\n",
    "infoplane_measure = 'upper'\n",
    "# infoplane_measure = 'bin'\n",
    "\n",
    "DO_SAVE        = True    # Whether to save plots or just show them\n",
    "DO_LOWER       = (infoplane_measure == 'lower')   # Whether to compute lower bounds also\n",
    "DO_BINNED      = (infoplane_measure == 'bin')     # Whether to compute MI estimates based on binning\n",
    "\n",
    "MAX_EPOCHS = 2000      # Max number of epoch for which to compute mutual information measure\n",
    "NUM_LABELS = 2\n",
    "# MAX_EPOCHS = 1000\n",
    "COLORBAR_MAX_EPOCHS = 2000\n",
    "\n",
    "# Directories from which to load saved layer activity\n",
    "ARCH = 'lstm'\n",
    "DIR_TEMPLATE = '%%s_%s'%ARCH\n",
    "\n",
    "# Functions to return upper and lower bounds on entropy of layer activity\n",
    "# noise_variance = 1e-3                    # Added Gaussian noise variance\n",
    "binsize = 0.07                           # size of bins for binning method\n",
    "Klayer_activity = K.placeholder(ndim=2)  # Keras placeholder \n",
    "entropy_func_upper = K.function([Klayer_activity,], [kde.entropy_estimator_kl(Klayer_activity, 1e-1),])\n",
    "entropy_func_lower = K.function([Klayer_activity,], [kde.entropy_estimator_bd(Klayer_activity, 1e-1),])\n",
    "\n",
    "# nats to bits conversion factor\n",
    "nats2bits = 1.0/np.log(2) \n",
    "\n",
    "# Save indexes of tests data for each of the output classes\n",
    "saved_labelixs = {}\n",
    "\n",
    "y = tst.y\n",
    "Y = tst.Y\n",
    "\n",
    "# Here the train and test set are concatenate, which means the MI is calculated based on the full data. \n",
    "# Perhaps, we can calculate it seperately in out report to see the difference\n",
    "if FULL_MI:\n",
    "    full = utils.construct_full_dataset(trn,tst)\n",
    "    y = full.y\n",
    "    Y = full.Y\n",
    "\n",
    "for i in range(NUM_LABELS):\n",
    "    saved_labelixs[i] = y == i\n",
    "    \n",
    "labelprobs = np.mean(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_LAYERS    = None     # Which layers to plot.  If None, all saved layers are plotted \n",
    "\n",
    "# Data structure used to store results\n",
    "measures = OrderedDict()\n",
    "measures['tanh'] = {}\n",
    "# measures['relu'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MI measures\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for activation in measures.keys():\n",
    "    cur_dir = 'rawdata/relu_lstm'\n",
    "    if not os.path.exists(cur_dir):\n",
    "        print(\"Directory %s not found\" % cur_dir)\n",
    "        continue\n",
    "        \n",
    "    # Load files saved during each epoch, and compute MI measures of the activity in that epoch\n",
    "    print('*** Doing %s ***' % cur_dir)\n",
    "    for epochfile in sorted(os.listdir(cur_dir)):\n",
    "        if not epochfile.startswith('epoch'):\n",
    "            continue\n",
    "            \n",
    "        fname = cur_dir + \"/\" + epochfile\n",
    "        with open(fname, 'rb') as f:\n",
    "            d = cPickle.load(f)\n",
    "\n",
    "        epoch = d['epoch']\n",
    "        if epoch in measures[activation]: # Skip this epoch if its already been processed\n",
    "            continue                      # this is a trick to allow us to rerun this cell multiple times)\n",
    "            \n",
    "        if epoch > MAX_EPOCHS:\n",
    "            continue\n",
    "\n",
    "        print(\"Doing\", fname)\n",
    "        \n",
    "        num_layers = len(d['data']['activity_tst'])\n",
    "\n",
    "        if PLOT_LAYERS is None:\n",
    "            PLOT_LAYERS = []\n",
    "            for lndx in range(num_layers):\n",
    "                #if d['data']['activity_tst'][lndx].shape[1] < 200 and lndx != num_layers - 1:\n",
    "                PLOT_LAYERS.append(lndx)\n",
    "                \n",
    "        cepochdata = defaultdict(list)\n",
    "        \n",
    "        noise_variance = 1e-1\n",
    "        max_activity = np.max(d['data']['activity_tst'][0])\n",
    "        for lndx in range(num_layers):\n",
    "            activity = d['data']['activity_tst'][lndx]\n",
    "            ada_noise_variance = noise_variance\n",
    "            \n",
    "#             ada_noise_variance = noise_variance*np.max(activity)\n",
    "\n",
    "            # Compute marginal entropies\n",
    "            h_upper = entropy_func_upper([activity, ada_noise_variance])[0]\n",
    "            if DO_LOWER:\n",
    "                h_lower = entropy_func_lower([activity, ada_noise_variance])[0]\n",
    "                \n",
    "            # Layer activity given input. This is simply the entropy of the Gaussian noise\n",
    "            hM_given_X = kde.kde_condentropy(activity, ada_noise_variance)\n",
    "\n",
    "            # Compute conditional entropies of layer activity given output\n",
    "            hM_given_Y_upper=0.\n",
    "            for i in range(NUM_LABELS):\n",
    "                hcond_upper = entropy_func_upper([activity[saved_labelixs[i],:], ada_noise_variance])[0]\n",
    "                hM_given_Y_upper += labelprobs[i] * hcond_upper\n",
    "                \n",
    "            if DO_LOWER:\n",
    "                hM_given_Y_lower=0.\n",
    "                for i in range(NUM_LABELS):\n",
    "                    hcond_lower = entropy_func_lower([activity[saved_labelixs[i],:], ada_noise_variance])[0]\n",
    "                    hM_given_Y_lower += labelprobs[i] * hcond_lower\n",
    "                \n",
    "            cepochdata['MI_XM_upper'].append( nats2bits * (h_upper - hM_given_X) )\n",
    "#             cepochdata['MI_XM_upper'].append( nats2bits * (h_upper) )\n",
    "            cepochdata['MI_YM_upper'].append( nats2bits * (h_upper - hM_given_Y_upper) )\n",
    "            cepochdata['H_M_upper'  ].append( nats2bits * h_upper )\n",
    "\n",
    "            pstr = 'upper: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_upper'][-1], cepochdata['MI_YM_upper'][-1])\n",
    "            if DO_LOWER:  # Compute lower bounds\n",
    "                cepochdata['MI_XM_lower'].append( nats2bits * (h_lower) )\n",
    "                cepochdata['MI_YM_lower'].append( nats2bits * (h_lower - hM_given_Y_lower) )\n",
    "                cepochdata['H_M_lower'  ].append( nats2bits * h_lower )\n",
    "                pstr += ' | lower: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_lower'][-1], cepochdata['MI_YM_lower'][-1])\n",
    "\n",
    "            if DO_BINNED: # Compute binned estimates\n",
    "                binxm, binym = simplebinmi.bin_calc_information2(saved_labelixs, activity, binsize)\n",
    "                cepochdata['MI_XM_bin'].append( nats2bits * binxm )\n",
    "                cepochdata['MI_YM_bin'].append( nats2bits * binym )\n",
    "                pstr += ' | bin: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_bin'][-1], cepochdata['MI_YM_bin'][-1])\n",
    "                        \n",
    "            print('- Layer %d %s' % (lndx, pstr) )\n",
    "\n",
    "        measures[activation][epoch] = cepochdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Infoplane Visualization\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_epoch = max( (max(vals.keys()) if len(vals) else 0) for vals in measures.values())\n",
    "sm = plt.cm.ScalarMappable(cmap='gnuplot', norm=plt.Normalize(vmin=0, vmax=COLORBAR_MAX_EPOCHS))\n",
    "sm._A = []\n",
    "\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "for actndx, (activation, vals) in enumerate(measures.items()):\n",
    "    epochs = sorted(vals.keys())\n",
    "    if not len(epochs):\n",
    "        continue\n",
    "    plt.subplot(1,2,actndx+1)\n",
    "    \n",
    "#     ylims = np.zeros((len(epochs),1))\n",
    "#     xlims = np.zeros((len(epochs),1))\n",
    "    for epoch in epochs:\n",
    "        c = sm.to_rgba(epoch)\n",
    "        xmvals = np.array(vals[epoch]['MI_XM_'+infoplane_measure])[PLOT_LAYERS]\n",
    "        ymvals = np.array(vals[epoch]['MI_YM_'+infoplane_measure])[PLOT_LAYERS]\n",
    "\n",
    "        plt.plot(xmvals, ymvals, c=c, alpha=0.1, zorder=1)\n",
    "        plt.scatter(xmvals, ymvals, s=20, facecolors=[c for _ in PLOT_LAYERS], edgecolor='none', zorder=2)\n",
    "        \n",
    "#         ylims[epoch] =  np.max(ymvals)\n",
    "#         xlims[epoch] =  np.max(xmvals)\n",
    "\n",
    "#     plt.ylim([0, np.max(ylims)])\n",
    "#     plt.xlim([0, np.max(xlims)])\n",
    "\n",
    "    plt.xlabel('I(X;M)')\n",
    "    plt.ylabel('I(Y;M)')\n",
    "    plt.title(activation)\n",
    "    \n",
    "# cbaxes = fig.add_axes([1.0, 0.125, 0.03, 0.8]) \n",
    "plt.colorbar(sm, label='Epoch')\n",
    "plt.tight_layout()\n",
    "\n",
    "if DO_SAVE:\n",
    "    plt.savefig(DIR_TEMPLATE % ('infoplane_'+activation+ARCH),bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
